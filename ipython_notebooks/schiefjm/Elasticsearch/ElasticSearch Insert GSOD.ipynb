{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: pylab import has clobbered these variables: ['f', 'random', 'bytes']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "from future.builtins import (bytes, str, open, super, range,\n",
    "                      zip, round, input, int, pow, object)\n",
    "\n",
    "if sys.version_info.major == 2:\n",
    "    # in Python 2 cPickle is much faster than pickle but doesn't \n",
    "    # deal w/ unicode\n",
    "    import cPickle as pickle\n",
    "else:\n",
    "    # Python 3 loads the faster pickle by default if it's available\n",
    "    import pickle\n",
    "\n",
    "# ---- Standard Libraries not included in pylab\n",
    "import collections\n",
    "import glob\n",
    "import json\n",
    "import random\n",
    "import time\n",
    "from StringIO import StringIO\n",
    "\n",
    "# ---- Extra Libraries for additional functionality\n",
    "import elasticsearch\n",
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "# -------1---------2---------3---------4---------5---------6---------7---------8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parse_observation(ob):\n",
    "    \"\"\" Given an observation (ob) as a string return a dictionary of the \n",
    "    observation with names and values.\n",
    "    \n",
    "    \"\"\"\n",
    "    header = [\"Station Id\", \"WBAN\", \"Date\", \"Mean Temp\", \"Num of Obs\", \"Dew Point\",\n",
    "              \"SLP\", \"STP\", \"Visibility\", \"Wind Speed\", \"Max Wind Speed\",\n",
    "              \"Gust\", \"Max Temp\", \"Min Temp\", \"Precipitation\", \"Snow Depth\", \"FRSHTT\"]\n",
    "    \n",
    "    ob = ob.strip(\"\\n\").split()\n",
    "    \n",
    "    # remove excess observation counts\n",
    "    for i in range(14, 4, -2): # backwards to preserve index nums\n",
    "        ob.pop(i)\n",
    "    \n",
    "    # add hyphens to date to enable elasticsearch to create a date from it\n",
    "    ob[2] = ob[2][0:4] + \"-\" + ob[2][4:6] + \"-\" + ob[2][6:8]\n",
    "    \n",
    "    # zip with header information into a dictionary and return it\n",
    "    return dict((element[0], element[1].strip(\"*\")) \n",
    "                           for element in zip(header, ob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def es_insert_year(index_name, year):\n",
    "    \"\"\" Given a year in the range 1929 to 2009 inclusive parses and inserts the\n",
    "    observations for that year into an elasticseach index of index_name.\n",
    "    \n",
    "    \"\"\"\n",
    "    es = Elasticsearch(['http://search-01.ec2.internal:9200'])\n",
    "    year = str(year)\n",
    "    gsod_dir = \"/home/schiefjm/weather/gsod/\" + year + \"/\"\n",
    "    \n",
    "    for file_name in glob.glob(gsod_dir + \"*\"):\n",
    "        with open(file_name, \"r\") as obs:\n",
    "            file_header = obs.readline()\n",
    "\n",
    "            for ob in obs:\n",
    "                es.index(\n",
    "                    index=index_name, \n",
    "                    doc_type=\"observation\", \n",
    "                    body=json.dumps(parse_observation(ob))\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "es = Elasticsearch(['http://search-01.ec2.internal:9200'])\n",
    "\n",
    "doc = {\n",
    "    'title': 'Test',\n",
    "    'text': 'This is some text to test with.'\n",
    "}\n",
    "\n",
    "result = es.index(\n",
    "             index = \"test_blog\", \n",
    "             doc_type = 'blog',\n",
    "             body = doc\n",
    "         )\n",
    "print(result['created'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "curl -XDELETE \"http://search-01.ec2.internal:9200/test_blog\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
