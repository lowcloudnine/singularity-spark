{
 "metadata": {
  "name": "",
  "signature": "sha256:e2ff4160395f168879d0bfb49d7179c84aa59cf42711b9270b9473e4cbb32d88"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from utils import header\n",
      "print(header.create_header(sc))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Test Name                              No\n",
        "Machine            c1-master.ec2.internal\n",
        "Date                          16 Feb 2015\n",
        "Start Time                       14:32:34\n",
        "\n",
        "Spark Configuration\n",
        "========================================================================\n",
        "spark.executor.extraLibraryPath\n",
        "    /opt/cloudera/parcels/CDH-5.3.1- .. 5.3.1.p0.5/lib/hadoop/lib/native\n",
        "spark.executor.memory\n",
        "    2g\n",
        "spark.driver.extraLibraryPath\n",
        "    /opt/cloudera/parcels/CDH-5.3.1- .. 5.3.1.p0.5/lib/hadoop/lib/native\n",
        "spark.executor.instances\n",
        "    8\n",
        "spark.serializer.objectStreamReset\n",
        "    100\n",
        "spark.eventLog.enabled\n",
        "    true\n",
        "spark.yarn.historyServer.address\n",
        "    http://c1-master.ec2.internal:18088\n",
        "spark.cores.max\n",
        "    8\n",
        "spark.rdd.compress\n",
        "    True\n",
        "spark.app.name\n",
        "    PySparkShell\n",
        "spark.eventLog.dir\n",
        "    hdfs://c1-master.ec2.internal:8020/user/spark/applicationHistory\n",
        "spark.master\n",
        "    yarn-client\n",
        "========================================================================\n",
        "\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ob_rdds = []\n",
      "for month in range(1, 13):\n",
      "    dtg = \"1970{:02}\".format(month)\n",
      "    obs = sc.textFile(\"/user/schiefjm/weather/gsod/1970\")\\\n",
      "            .filter(lambda line: \"STN\" not in line)\\\n",
      "            .filter(lambda line: \"034700\" in line)\\\n",
      "            .filter(lambda line: dtg in line)\n",
      "    ob_rdds.append([dtg, obs.take(obs.count())])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_stations(year):\n",
      "    \"\"\" Given a year from 1929 to 2009 inclusive returns a set of the \n",
      "    stations in the data set for that year. \n",
      "    \n",
      "    :input:\n",
      "        year: a string or integer between 1929 and 2009 inclusive\n",
      "        \n",
      "    :output:\n",
      "        returns a list of tuples of the station id and number of obs for\n",
      "        said station\n",
      "    \"\"\"\n",
      "    # validate the year\n",
      "    year = int(year)\n",
      "    if 1929 <= year <= 2009:\n",
      "        year = str(year)\n",
      "    else:\n",
      "        print(\"Please enter a valid year from 1929 to 2009.\")\n",
      "        return 0\n",
      "    \n",
      "    # get the stations and number of obs for each\n",
      "    return sc.textFile(\"/user/schiefjm/weather/gsod/\" + year)\\\n",
      "             .filter(lambda line: \"STN\" not in line)\\\n",
      "             .map(lambda line: (line.split()[0], 1))\\\n",
      "             .reduceByKey(lambda x, y: x + y)\\\n",
      "             .collect()\n",
      "\n",
      "for year in range(1929, 1932):\n",
      "    stations = get_stations(year)\n",
      "    total_obs = 0\n",
      "    for station in stations:\n",
      "        total_obs += int(station[1])\n",
      "    print(\"\\n{} has {} stations and {} total observations\"\\\n",
      "          .format(year, len(stations), total_obs))\n",
      "    print(\"-\" * 70)\n",
      "    for station in stations[:5]:\n",
      "        print(\"{}\\t{}\".format(station[0], station[1]))\n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1929 has 21 stations and 2081 total observations\n",
        "----------------------------------------------------------------------\n",
        "038040\t91\n",
        "039730\t89\n",
        "990061\t44\n",
        "033790\t148\n",
        "037950\t149\n",
        "\n",
        "1930 has 23 stations and 7285 total observations"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "----------------------------------------------------------------------\n",
        "039530\t363\n",
        "030750\t357\n",
        "030910\t190\n",
        "038640\t361\n",
        "035590\t1\n",
        "\n",
        "1931 has 31 stations and 9913 total observations"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "----------------------------------------------------------------------\n",
        "105130\t196\n",
        "030260\t358\n",
        "122050\t359\n",
        "104160\t144\n",
        "037950\t352\n"
       ]
      }
     ],
     "prompt_number": 51
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "counts = file.flatMap(lambda line: line.split(\" \")) \\\n",
      "             .map(lambda word: (word, 1)) \\\n",
      "             .reduceByKey(lambda a, b: a + b)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}