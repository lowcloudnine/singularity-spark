{
 "metadata": {
  "name": "",
  "signature": "sha256:119776ab30ec9ef92551502fbb06efd0b9e5aea094834f9802757d52f2a8c6d3"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sc"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 1,
       "text": [
        "<pyspark.context.SparkContext at 0x7f51ffe5c290>"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def sparkcontext_info(sc):\n",
      "    settings = []\n",
      "    \n",
      "    settings.append(\"Spark Configuration\\n\")\n",
      "    settings.append(\"=\" * 72 + \"\\n\")\n",
      "    for name, value in sc._conf.getAll():\n",
      "        if len(value) > 68:\n",
      "            value = value[:32] + \" .. \" + value[-32:]\n",
      "        settings.append(\"{:<30}\\n    {:>}\\n\".format(name, value))\n",
      "    settings.append(\"=\" * 72 + \"\\n\")\n",
      "    \n",
      "    return \"\".join(settings)\n",
      "\n",
      "print(sparkcontext_info(sc))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Spark Configuration\n",
        "========================================================================\n",
        "spark.executor.extraLibraryPath\n",
        "    /opt/cloudera/parcels/CDH-5.3.1- .. 5.3.1.p0.5/lib/hadoop/lib/native\n",
        "spark.executor.memory         \n",
        "    2g\n",
        "spark.driver.extraLibraryPath \n",
        "    /opt/cloudera/parcels/CDH-5.3.1- .. 5.3.1.p0.5/lib/hadoop/lib/native\n",
        "spark.executor.instances      \n",
        "    8\n",
        "spark.serializer.objectStreamReset\n",
        "    100\n",
        "spark.eventLog.enabled        \n",
        "    true\n",
        "spark.yarn.historyServer.address\n",
        "    http://c1-master.ec2.internal:18088\n",
        "spark.cores.max               \n",
        "    8\n",
        "spark.rdd.compress            \n",
        "    True\n",
        "spark.app.name                \n",
        "    PySparkShell\n",
        "spark.eventLog.dir            \n",
        "    hdfs://c1-master.ec2.internal:8020/user/spark/applicationHistory\n",
        "spark.master                  \n",
        "    yarn-client\n",
        "========================================================================\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "obs = sc.textFile(\"/user/schiefjm/weather/gsod/1929\")\n",
      "obs.count()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "2102"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}