{
 "metadata": {
  "name": "",
  "signature": "sha256:19b95a169abdeacf41531c9cdb18b7d4f17f523756b9376d5fd5220ee64f15c5"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "\n",
      "cd /home/schiefjm\n",
      "for arg in $(ls)\n",
      "do\n",
      "    echo $arg\n",
      "done"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "cloudera\n",
        "downloads\n",
        "log_generator\n",
        "projects\n",
        "weather\n",
        "wikipedia\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash \n",
      "\n",
      "cd /home/schiefjm/projects/singularity-spark/ipy_server_setup/\n",
      "for file in $(ls)\n",
      "do \n",
      "    cat $file\n",
      "done"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "import os\n",
        "import sys\n",
        "\n",
        "spark_home = os.environ.get(\"SPARK_HOME\", None)\n",
        "if not spark_home:\n",
        "    raise ValueError(\"SPARK_HOME environment variable is not set.\")\n",
        "\n",
        "sys.path.insert(0, os.path.join(spark_home, \"python\"))\n",
        "sys.path.insert(0, os.path.join(spark_home, 'python/lib/py4j-0.8.2.1-src.zip'))\n",
        "\n",
        "execfile(os.path.join(spark_home, 'python/pyspark/shell.py'))\n",
        "#-----------------------------------------------------------------------------\n",
        "# Python Environment Settings\n",
        "#-----------------------------------------------------------------------------\n",
        "\n",
        "# Anaconda 2.1.0 Python 2.7 Settings\n",
        "export PATH=\"/usr/local/anaconda/bin\":$PATH\n",
        "\n",
        "# Scala 2.10.4 Settings\n",
        "export PATH=\"/usr/local/scala/bin\":$PATH\n",
        "export SCALA_HOME=\"/usr/local/scala/bin\"\n",
        "\n",
        "#-----------------------------------------------------------------------------\n",
        "# Cloudera/Hadoop/Spark/PySpark Settings\n",
        "#-----------------------------------------------------------------------------\n",
        "\n",
        "# Hadoop alias\n",
        "alias hfs='hdfs dfs'\n",
        "export HADOOP_CONF_DIR=/etc/hadoop/conf\n",
        "\n",
        "# Spark Configurations\n",
        "export SPARK_HOME='/opt/cloudera/parcels/CDH/lib/spark'\n",
        "export PYSPARK_PYTHON='/usr/local/anaconda/bin/python'\n",
        "export SPARK_YARN_USER_ENV=\"$PYSPARK_PYTHON\"\n",
        "export SPARK_MASTER_IP=\"not ip but machine name, ie. c5-master.internal\"\"\n",
        "export SPARK_MASTER_PORT=\"7077\"\n",
        "# for custom spark logging levels, etc.\n",
        "export SPARK_CONF_DIR=\"/path/to/.spark/conf/\"\n",
        "\n",
        "# MASTER=\"--master spark://master_spark_machine_name:7077 \"\n",
        "MASTER=\"--master local[*] \"\n",
        "CLASS=\"--deploy-mode client \"\n",
        "NAME=\"--name IPY_NB_SPARK \"\n",
        "MEMORY=\"--driver-memory 2g \"\n",
        "EXMEM=\"--executor-memory 2g \"\n",
        "CORES=\"--driver-cores 4 \"\n",
        "\n",
        "# export PYSPARK_SUBMIT_ARGS=\"$MASTER $CLASS $NAME $MEMORY $EXMEM $CORES\"\n",
        "export PYSPARK_SUBMIT_ARGS=\"$MASTER\"\n",
        "\n",
        "# Configuration file for ipython-notebook.\n",
        "\n",
        "c = get_config()\n",
        "\n",
        "# The IP address the notebook server will listen on.\n",
        "c.NotebookApp.ip = '*'\n",
        "\n",
        "c.NotebookApp.open_browser = False\n",
        "\n",
        "# The port the notebook server will listen on.\n",
        "c.NotebookApp.port = 8081\n",
        "\n",
        "# The full path to an SSL/TLS certificate file.\n",
        "c.NotebookApp.certfile = u'/path/to/.ipython/profile_pyspark/nbcert.pem'\n",
        "\n",
        "# The string should be of the form type:salt:hashed-password.\n",
        "PWDFILE='/path/to/.ipython/profile_pyspark/nbpasswd.txt'\n",
        "c.NotebookApp.password = open(PWDFILE).read().strip()\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "\n",
      "FNAME=\"/home/schiefjm/.bashrc\"\n",
      "\n",
      "if [ -f $FNAME ]\n",
      "then\n",
      "    wc $FNAME | awk '{print $1}' \n",
      "fi"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "92\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash \n",
      "\n",
      "sudo /usr/local/anaconda/bin/pip install ipython"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Requirement already satisfied (use --upgrade to upgrade): ipython in /usr/local/anaconda/lib/python2.7/site-packages\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}