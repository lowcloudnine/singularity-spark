{
 "metadata": {
  "name": "",
  "signature": "sha256:e5d192f6bc81a49ae3a355be2c6352fb063c2d07084ae4f9fa35e9f78f5c0e4b"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Imports"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%pylab inline\n",
      "\n",
      "from __future__ import absolute_import\n",
      "from __future__ import division\n",
      "from __future__ import print_function\n",
      "\n",
      "from future.builtins import (bytes, str, open, super, range,\n",
      "                      zip, round, input, int, pow, object)\n",
      "\n",
      "if sys.version_info.major == 2:\n",
      "    # in Python 2 cPickle is much faster than pickle but doesn't deal w/ unicode\n",
      "    import cPickle as pickle\n",
      "else:\n",
      "    # Python 3 loads the faster pickle by default if it's available\n",
      "    import pickle\n",
      "\n",
      "import collections\n",
      "import random\n",
      "import time"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Populating the interactive namespace from numpy and matplotlib\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "SparkContext Info"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from utils import header\n",
      "print(header.create_header(sc))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Test Name                              No\n",
        "Machine            c1-master.ec2.internal\n",
        "Date                          19 Feb 2015\n",
        "Start Time                       16:19:43\n",
        "\n",
        "Spark Configuration\n",
        "========================================================================\n",
        "spark.executor.extraLibraryPath\n",
        "    /opt/cloudera/parcels/CDH-5.3.1- .. 5.3.1.p0.5/lib/hadoop/lib/native\n",
        "spark.executor.memory\n",
        "    2g\n",
        "spark.driver.extraLibraryPath\n",
        "    /opt/cloudera/parcels/CDH-5.3.1- .. 5.3.1.p0.5/lib/hadoop/lib/native\n",
        "spark.executor.instances\n",
        "    8\n",
        "spark.serializer.objectStreamReset\n",
        "    100\n",
        "spark.eventLog.enabled\n",
        "    true\n",
        "spark.yarn.historyServer.address\n",
        "    http://c1-master.ec2.internal:18088\n",
        "spark.cores.max\n",
        "    8\n",
        "spark.rdd.compress\n",
        "    True\n",
        "spark.app.name\n",
        "    PySparkShell\n",
        "spark.eventLog.dir\n",
        "    hdfs://c1-master.ec2.internal:8020/user/spark/applicationHistory\n",
        "spark.master\n",
        "    yarn-client\n",
        "========================================================================\n",
        "\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Filter Functions for RDDs"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def is_ob(ob):\n",
      "    return \"STN\" not in ob\n",
      "\n",
      "def is_station(station_id, ob):\n",
      "    return station_id in ob\n",
      "\n",
      "def obs_by_station(obs_rdd):\n",
      "    \"\"\" Given an RDD of observations from GSOD returns a dictionary of the observations\n",
      "    the key is the station id and the value is an array of the observations for that\n",
      "    station.\n",
      "    \n",
      "    \"\"\"\n",
      "    stations = obs_rdd.map(lambda line: (line.split()[0], 1))\\\n",
      "                      .reduceByKey(lambda x, y: x + y)\\\n",
      "                      .collect()\n",
      "    \n",
      "    station_obs = {}\n",
      "    for station in stations:\n",
      "        station_id = str(station[0])\n",
      "        station_obs[station_id] = \\\n",
      "            obs_rdd.filter(lambda line: is_station(station_id, line))\\\n",
      "                   .collect()\n",
      "        \n",
      "    return station_obs\n",
      "\n",
      "def obs_by_year(years):\n",
      "    \"\"\" Given a list of years returns an ordered dictionary of the years with a value of\n",
      "    a dictionary of station_ids with the value of observations.\n",
      "    \n",
      "    \"\"\"\n",
      "    years_of_obs = collections.OrderedDict()\n",
      "    for year in years:\n",
      "        obs_rdd = sc.textFile(\"/user/schiefjm/weather/gsod/\" + str(year))\\\n",
      "                    .filter(lambda line: is_ob(line))\n",
      "        obs_dict = collections.OrderedDict(obs_by_station(obs_rdd))\n",
      "        years_of_obs[year] = obs_dict\n",
      "    \n",
      "    return years_of_obs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "structured_obs = obs_by_year([year for year in range(1929, 1930)])\n",
      "sys.getsizeof(structured_obs)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "280"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "persistent_stations = set()\n",
      "\n",
      "years = [key for key in structured_obs]\n",
      "for year in years:\n",
      "    for key in structured_obs[year]:\n",
      "        persistent_stations.add(key)\n",
      "\n",
      "print(len(persistent_stations))\n",
      "for station in sorted(persistent_stations):\n",
      "    # print(station)\n",
      "    pass"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "21\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for year in range(1929, 1933):\n",
      "    stations = sc.textFile(\"/user/schiefjm/weather/gsod/\" + str(year))\\\n",
      "                 .filter(lambda line: \"STN\" not in line)\\\n",
      "                 .map(lambda line: (line.split()[0], 1))\\\n",
      "                 .reduceByKey(lambda x, y: x + y)\\\n",
      "                 .collect()\n",
      "    \n",
      "    print(year, len(set(stations)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1929 21\n",
        "1930"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 23\n",
        "1931"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 31\n",
        "1932"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 39\n"
       ]
      }
     ],
     "prompt_number": 6
    }
   ],
   "metadata": {}
  }
 ]
}